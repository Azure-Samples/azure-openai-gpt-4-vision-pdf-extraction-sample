{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Using Azure OpenAI GPT-4 Vision to extract structured JSON data from PDF documents\n",
                "\n",
                "This notebook demonstrates [how to use GPT-4 Vision](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/gpt-with-vision?tabs=rest) to extract structured JSON data from PDF documents, such as invoices, using the [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview).\n",
                "\n",
                "## Pre-requisites\n",
                "\n",
                "The notebook uses [PowerShell](https://learn.microsoft.com/powershell/scripting/install/installing-powershell) and [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to deploy all necessary Azure resources. Both tools are available on Windows, macOS and Linux environments. It also uses [.NET 8](https://dotnet.microsoft.com/download/dotnet/8.0) to run the C# code that interacts with the Azure OpenAI Service.\n",
                "\n",
                "Running this notebook will deploy the following resources in your Azure subscription:\n",
                "- Azure Resource Group\n",
                "- Azure OpenAI Service (Sweden Central)\n",
                "- GPT-4 Vision model deployment (50K capacity)\n",
                "\n",
                "**Note**: The GPT-4 with Vision model is not available in all Azure OpenAI regions. For more information, see the [Azure OpenAI Service documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#standard-deployment-model-availability)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Deploy infrastructure with Az CLI & Bicep\n",
                "\n",
                "The following will prompt you to login to Azure. Once logged in, the current default subscription in your available subscriptions will be set for deployment.\n",
                "\n",
                "> **Note:** If you have multiple subscriptions, you can change the default subscription by running `az account set --subscription <subscription_id>`.\n",
                "\n",
                "Then, all the necessary Azure resources will be deployed, previously listed, using [Azure Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/).\n",
                "\n",
                "The deployment occurs at the subscription level, creating a new resource group. The location of the deployment is set to **Sweden Central** and this can be changed to another location that supports the GPT-4 Turbo with Vision model, as well as other parameters, in the [`./infra/main.bicepparam`](./infra/main.bicepparam) file.\n",
                "\n",
                "Once deployed, the Azure OpenAI Service endpoint and key will be stored in the [`./config.env`](./config.env) file for use in the .NET code.\n",
                "\n",
                "### Understanding the deployment\n",
                "\n",
                "#### Managed Identity\n",
                "\n",
                "A [user-assigned Managed Identity](https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview) is created for authenticating with Azure OpenAI instead of using API keys by using role-based access control (RBAC) permissions.\n",
                "\n",
                "Read more about [how to configure Azure OpenAI Service with managed identities](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity).\n",
                "\n",
                "#### OpenAI Services\n",
                "\n",
                "An [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview) instance is deployed in the Sweden Central region. This is deployed with the `gpt-4 (turbo-2024-04-09)` model to be used for inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "dotnet_interactive": {
                    "language": "pwsh"
                },
                "polyglot_notebook": {
                    "kernelName": "pwsh"
                },
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "$loggedIn = az account show --query \"name\" -o tsv\n",
                "\n",
                "if ($loggedIn -ne $null) {\n",
                "    Write-Host \"Already logged in as $loggedIn\"\n",
                "} else {\n",
                "    Write-Host \"Logging in...\"\n",
                "    az login\n",
                "}\n",
                "\n",
                "# Retrieve the default subscription ID\n",
                "$subscriptionId = (\n",
                "    (\n",
                "        az account list -o json `\n",
                "            --query \"[?isDefault]\"\n",
                "    ) | ConvertFrom-Json\n",
                ").id\n",
                "\n",
                "# Set the subscription\n",
                "az account set --subscription $subscriptionId\n",
                "Write-Host \"Subscription set to $subscriptionId\"\n",
                "\n",
                "$deploymentName = 'gpt-4-document-extraction'\n",
                "$location = 'swedencentral'\n",
                "\n",
                "$deploymentOutputs = (.\\Setup-Environment.ps1 -DeploymentName $deploymentName -Location $location -SkipInfrastructure $true)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install .NET dependencies\n",
                "\n",
                "This notebook uses .NET to interact with the Azure OpenAI Service. It takes advantage of the following NuGet packages:\n",
                "\n",
                "### PDFtoImage\n",
                "\n",
                "The [PDFtoImage](https://github.com/sungaila/PDFtoImage) library is used to convert PDF documents to JPEG images. The library provides a simple layer to convert PDF documents using the static `PDFtoImage.Conversion` class. Reading the bytes of the PDF, the library will create an image and store it with a given file name.\n",
                "\n",
                "### DotNetEnv\n",
                "\n",
                "The [DotNetEnv](https://github.com/tonerdo/dotnet-env) library is used to load environment variables from a `.env` file which can be accessed via the `Environment.GetEnvironmentVariable(string)` method. This library is used to load the Azure OpenAI Service endpoint, key and model deployment name from the [`./config.env`](./config.env) file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "dotnet_interactive": {
                    "language": "csharp"
                },
                "polyglot_notebook": {
                    "kernelName": "csharp"
                },
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "#r \"nuget:System.Text.Json, 8.0.1\"\n",
                "#r \"nuget:Azure.AI.OpenAI, 1.0.0-beta.17\"\n",
                "#r \"nuget:Azure.Identity, 1.11.3\"\n",
                "#r \"nuget:DotNetEnv, 3.0.0\"\n",
                "#r \"nuget:PDFtoImage, 4.0.1\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "dotnet_interactive": {
                    "language": "csharp"
                },
                "polyglot_notebook": {
                    "kernelName": "csharp"
                },
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "using System.Net;\n",
                "using System.Net.Http;\n",
                "using System.Text.Json.Nodes;\n",
                "using System.Text.Json;\n",
                "using System.IO; \n",
                "\n",
                "using Azure;\n",
                "using Azure.AI.OpenAI;\n",
                "using Azure.Core;\n",
                "using Azure.Identity;\n",
                "using DotNetEnv;\n",
                "using PDFtoImage;\n",
                "using SkiaSharp;"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "dotnet_interactive": {
                    "language": "csharp"
                },
                "polyglot_notebook": {
                    "kernelName": "csharp"
                },
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "Env.Load(\"config.env\");\n",
                "\n",
                "var endpoint = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\");\n",
                "var modelDeployment = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_COMPLETION_MODEL_DEPLOYMENT_NAME\");\n",
                "var apiVersion = \"2024-03-01-preview\";\n",
                "\n",
                "string visionEndpoint = $\"{endpoint}openai/deployments/{modelDeployment}/chat/completions?api-version={apiVersion}\";\n",
                "\n",
                "var credential = new DefaultAzureCredential(new DefaultAzureCredentialOptions { \n",
                "    ExcludeEnvironmentCredential = true,\n",
                "    ExcludeManagedIdentityCredential = true,\n",
                "    ExcludeSharedTokenCacheCredential = true,\n",
                "    ExcludeInteractiveBrowserCredential = true,\n",
                "    ExcludeAzurePowerShellCredential = true,\n",
                "    ExcludeVisualStudioCodeCredential = false,\n",
                "    ExcludeAzureCliCredential = false\n",
                "});\n",
                "\n",
                "var bearerToken = credential.GetToken(new TokenRequestContext(new[] { \"https://cognitiveservices.azure.com/.default\" })).Token;\n",
                "\n",
                "var pdfName = \"Invoice_1.pdf\";\n",
                "var pdfJsonExtractionName = $\"{pdfName}.Extraction.json\";"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Convert PDF to image\n",
                "\n",
                "For the GPT-4 with Vision model to extract structured JSON data from a PDF document, the document must first be converted to an image. The following code demonstrates how to convert a PDF document to a JPEG image using the `PDFtoImage` library.\n",
                "\n",
                "### Important notes for image analysis with the GPT-4 with Vision model\n",
                "\n",
                "- The maximum size for images is restricted to 20MB.\n",
                "- The `image_url` parameter in the message body has a `detail` property that can be set to `low` to enable a lower resolution image analysis for faster results with fewer tokens. However, this could impact the accuracy of the result.\n",
                "- When providing images, there is a limit of 10 images per call.\n",
                "\n",
                "Based on these notes, you may need to perform pre-processing of your PDF when converting it to images to ensure that the images are within the size limits and that the resolution is appropriate for the analysis. This may include:\n",
                "\n",
                "- Reducing the resolution of the images.\n",
                "- Splitting the PDF into multiple images, if it contains less than 10 pages.\n",
                "- Stitching multiple images together, if the PDF contains more than 10 pages.\n",
                "- Compressing the images to reduce the file size.\n",
                "\n",
                "Experiment with different pre-processing techniques to find the best approach for your specific use case.\n",
                "\n",
                "The following code provides examples using .NET to convert a PDF document with multiple pages into one image that stitches the pages together."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "dotnet_interactive": {
                    "language": "csharp"
                },
                "polyglot_notebook": {
                    "kernelName": "csharp"
                },
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "var pdf = await File.ReadAllBytesAsync(pdfName);\n",
                "var pageImages = PDFtoImage.Conversion.ToImages(pdf);\n",
                "\n",
                "var totalPageCount = pageImages.Count();\n",
                "\n",
                "// If there are more than 10 pages, we need to stitch images together so that the total number of pages is less than or equal to 10\n",
                "int maxSize = (int)Math.Ceiling(totalPageCount / 10.0);\n",
                "var pageImageGroups = new List<List<SKBitmap>>();\n",
                "for (int i = 0; i < totalPageCount; i += maxSize)\n",
                "{\n",
                "    var pageImageGroup = pageImages.Skip(i).Take(maxSize).ToList();\n",
                "    pageImageGroups.Add(pageImageGroup);\n",
                "}\n",
                "\n",
                "var pdfImageFiles = new List<string>();\n",
                "\n",
                "var count = 0;\n",
                "foreach (var pageImageGroup in pageImageGroups)\n",
                "{\n",
                "    var pdfImageName = $\"{pdfName}.Part_{count}.jpg\";\n",
                "\n",
                "    int totalHeight = pageImageGroup.Sum(image => image.Height);\n",
                "    int width = pageImageGroup.Max(image => image.Width);\n",
                "    var stitchedImage = new SKBitmap(width, totalHeight);\n",
                "    var canvas = new SKCanvas(stitchedImage);\n",
                "    int currentHeight = 0;\n",
                "    foreach (var pageImage in pageImageGroup)\n",
                "    {\n",
                "        canvas.DrawBitmap(pageImage, 0, currentHeight);\n",
                "        currentHeight += pageImage.Height;\n",
                "    }\n",
                "    using (var stitchedFileStream = new FileStream(pdfImageName, FileMode.Create, FileAccess.Write))\n",
                "    {\n",
                "        stitchedImage.Encode(stitchedFileStream, SKEncodedImageFormat.Jpeg, 100);\n",
                "    }\n",
                "    pdfImageFiles.Add(pdfImageName);\n",
                "    count++;\n",
                "\n",
                "    Console.WriteLine($\"Saved image to {pdfImageName}\");\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Use GPT-4 with Vision to extract the data from the image\n",
                "\n",
                "Now that the PDF document has been converted to an image, the GPT-4 with Vision model can be used to extract structured JSON data from the image. The following code demonstrates how to use the deployed Azure OpenAI Service directly via the API to extract structured JSON data from the image.\n",
                "\n",
                "In this example, the payload for the Chat completion endpoint is a JSON object with the following details:\n",
                "\n",
                "### System Prompt\n",
                "\n",
                "The system prompt is the instruction to the model that prescribes the model's behavior. They allow you to constrain the model's behavior to a specific task, making it more adaptable for specific use cases, such as extracting structured JSON data from documents.\n",
                "\n",
                "In this case, it is to extract structured JSON data from the image. Here is what we have provided:\n",
                "\n",
                "**You are an AI assistant that extracts data from documents and returns them as structured JSON objects. Do not return as a code block.**\n",
                "\n",
                "> **Note:** To avoid the response being returned as a code block, we have included the instruction to not return as a code block. \n",
                "\n",
                "Learn more about [system prompts](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message).\n",
                "\n",
                "### User Prompt\n",
                "\n",
                "The user prompt is the input to the model that provides context for the model's response. It is the input that the model uses to generate a response. \n",
                "\n",
                "In this case, it is the image of the document plus some additional text context to help the model understand the task.\n",
                "\n",
                "In order to extract structured JSON data, we need to provide the expected structure of the response. We can do this by creating our data transfer object (DTO) and providing a serialized, empty version of it in the user prompt.\n",
                "\n",
                "Here is what we have provided:\n",
                "\n",
                "**Extract the data from this invoice. If a value is not present, provide null. Use the following structure: {\"InvoiceNumber\":\"\",\"PurchaseOrderNumber\":\"\",\"CustomerName\":\"\",\"CustomerAddress\":\"\",\"DeliveryDate\":\"\",\"PayableBy\":\"\",\"Products\":[{\"Id\":\"\",\"Description\":\"\",\"UnitPrice\":0,\"Quantity\":0,\"Total\":0}],\"TotalQuantity\":0,\"TotalPrice\":0,\"Returns\":[{\"Id\":\"\",\"Description\":\"\",\"Quantity\":0,\"Reason\":\"\"}],\"ProductsSignatures\":[{\"Type\":\"\",\"Name\":\"\",\"IsSigned\":false}],\"ReturnsSignatures\":[{\"Type\":\"\",\"Name\":\"\",\"IsSigned\":false}]}**\n",
                "\n",
                "> **Note:** For the user prompt, it is ideal to provide a structure for the JSON response. Without one, the model will determine this for you and you may not get consistency across responses. \n",
                "\n",
                "This prompt ensures that the model understands the task, and the additional text context provides the model with the necessary information to extract the structured JSON data from the image. This approach would result in a response similar to the following:\n",
                "\n",
                "```json\n",
                "{\n",
                "  \"InvoiceNumber\": \"3847193\",\n",
                "  \"PurchaseOrderNumber\": \"15931\",\n",
                "  \"CustomerName\": \"Sharp Consulting\",\n",
                "  \"CustomerAddress\": \"73 Regal Way, Leeds, LS1 5AB, UK\",\n",
                "  \"DeliveryDate\": \"2024-05-16T00:00:00\",\n",
                "  \"PayableBy\": \"2024-05-24\",\n",
                "  \"Products\": [\n",
                "    {\n",
                "      \"Id\": \"PPR006\",\n",
                "      \"Description\": \"UNIT A4 80gsm\",\n",
                "      \"UnitPrice\": 25.86,\n",
                "      \"Quantity\": 5,\n",
                "      \"Total\": 129.30,\n",
                "      \"Reason\": null\n",
                "    },\n",
                "    {\n",
                "      \"Id\": \"3M12\",\n",
                "      \"Description\": \"NOTES 51x76mm Y\",\n",
                "      \"UnitPrice\": 3.00,\n",
                "      \"Quantity\": 12,\n",
                "      \"Total\": 36.00,\n",
                "      \"Reason\": null\n",
                "    }\n",
                "  ],\n",
                "  \"Returns\": [\n",
                "    {\n",
                "      \"Id\": \"MA145\",\n",
                "      \"Description\": \"POSTAL TUBE BROWN\",\n",
                "      \"UnitPrice\": null,\n",
                "      \"Quantity\": 1,\n",
                "      \"Total\": null,\n",
                "      \"Reason\": \"Previous order has sufficient stock, no replacement required.\"\n",
                "    },\n",
                "    {\n",
                "      \"Id\": \"JF7902\",\n",
                "      \"Description\": \"MAILBOX 25PK\",\n",
                "      \"UnitPrice\": null,\n",
                "      \"Quantity\": 1,\n",
                "      \"Total\": null,\n",
                "      \"Reason\": \"Not required.\"\n",
                "    }\n",
                "  ],\n",
                "  \"TotalQuantity\": 66,\n",
                "  \"TotalPrice\": 1075.70,\n",
                "  \"ProductsSignatures\": [\n",
                "    {\n",
                "      \"Type\": \"Customer\",\n",
                "      \"Name\": \"Sarah H.\",\n",
                "      \"IsSigned\": true\n",
                "    },\n",
                "    {\n",
                "      \"Type\": \"Driver\",\n",
                "      \"Name\": \"James T\",\n",
                "      \"IsSigned\": true\n",
                "    }\n",
                "  ],\n",
                "  \"ReturnsSignatures\": [\n",
                "    {\n",
                "      \"Type\": \"Customer\",\n",
                "      \"Name\": \"Sarah H.\",\n",
                "      \"IsSigned\": true\n",
                "    },\n",
                "    {\n",
                "      \"Type\": \"Driver\",\n",
                "      \"Name\": \"James T\",\n",
                "      \"IsSigned\": true\n",
                "    }\n",
                "  ]\n",
                "}\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "public class InvoiceData\n",
                "{\n",
                "    public string? InvoiceNumber { get; set; }\n",
                "\n",
                "    public string? PurchaseOrderNumber { get; set; }\n",
                "\n",
                "    public string? CustomerName { get; set; }\n",
                "\n",
                "    public string? CustomerAddress { get; set; }\n",
                "\n",
                "    public DateTime? DeliveryDate { get; set; }\n",
                "\n",
                "    public DateTime? PayableBy { get; set; }\n",
                "\n",
                "    public IEnumerable<InvoiceDataProduct>? Products { get; set; }\n",
                "\n",
                "    public IEnumerable<InvoiceDataProduct>? Returns { get; set; }\n",
                "\n",
                "    public double? TotalQuantity { get; set; }\n",
                "\n",
                "    public double? TotalPrice { get; set; }\n",
                "\n",
                "    public IEnumerable<InvoiceDataSignature>? ProductsSignatures { get; set; }\n",
                "\n",
                "    public IEnumerable<InvoiceDataSignature>? ReturnsSignatures { get; set; }\n",
                "\n",
                "    public static InvoiceData Empty => new()\n",
                "    {\n",
                "        InvoiceNumber = string.Empty,\n",
                "        PurchaseOrderNumber = string.Empty,\n",
                "        CustomerName = string.Empty,\n",
                "        CustomerAddress = string.Empty,\n",
                "        DeliveryDate = DateTime.MinValue,\n",
                "        Products =\n",
                "            new List<InvoiceDataProduct> { new() { Id = string.Empty, Description = string.Empty, UnitPrice = 0.0, Quantity = 0.0, Total = 0.0 } },\n",
                "        Returns =\n",
                "            new List<InvoiceDataProduct> { new() { Id = string.Empty, Quantity = 0.0, Reason = string.Empty } },\n",
                "        TotalQuantity = 0,\n",
                "        TotalPrice = 0,\n",
                "        ProductsSignatures = new List<InvoiceDataSignature>\n",
                "        {\n",
                "            new()\n",
                "            {\n",
                "                Type = string.Empty,\n",
                "                Name = string.Empty,\n",
                "                IsSigned = false\n",
                "            }\n",
                "        },\n",
                "        ReturnsSignatures = new List<InvoiceDataSignature>\n",
                "        {\n",
                "            new()\n",
                "            {\n",
                "                Type = string.Empty,\n",
                "                Name = string.Empty,\n",
                "                IsSigned = false\n",
                "            }\n",
                "        }\n",
                "    };\n",
                "\n",
                "    public class InvoiceDataProduct\n",
                "    {\n",
                "        public string? Id { get; set; }\n",
                "\n",
                "        public string? Description { get; set; }\n",
                "\n",
                "        public double? UnitPrice { get; set; }\n",
                "\n",
                "        public double Quantity { get; set; }\n",
                "\n",
                "        public double? Total { get; set; }\n",
                "\n",
                "        public string? Reason { get; set; }\n",
                "    }\n",
                "\n",
                "    public class InvoiceDataSignature\n",
                "    {\n",
                "        public string? Type { get; set; }\n",
                "\n",
                "        public string? Name { get; set; }\n",
                "\n",
                "        public bool? IsSigned { get; set; }\n",
                "    }\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "var userPromptParts = new List<JsonNode>{\n",
                "    new JsonObject\n",
                "    {\n",
                "        { \"type\", \"text\" },\n",
                "        { \"text\", $\"Extract the data from this invoice. If a value is not present, provide null. Reasons may overlap multiple lines, arrows indicate which reason relates to which line item. Use the following structure:{JsonSerializer.Serialize(InvoiceData.Empty)}\" }\n",
                "    }\n",
                "};\n",
                "\n",
                "foreach (var pdfImageFile in pdfImageFiles)\n",
                "{\n",
                "    var imageBytes = await File.ReadAllBytesAsync(pdfImageFile);\n",
                "    var base64Image = Convert.ToBase64String(imageBytes);\n",
                "    userPromptParts.Add(new JsonObject\n",
                "    {\n",
                "        { \"type\", \"image_url\" },\n",
                "        { \"image_url\", new JsonObject { { \"url\", $\"data:image/jpeg;base64,{base64Image}\" } } }\n",
                "    });\n",
                "}\n",
                "\n",
                "JsonObject jsonPayload = new JsonObject\n",
                "{\n",
                "    {\n",
                "        \"messages\", new JsonArray \n",
                "        {\n",
                "            new JsonObject\n",
                "            {\n",
                "                { \"role\", \"system\" },\n",
                "                { \"content\", \"You are an AI assistant that extracts data from documents and returns them as structured JSON objects. Do not return as a code block.\" }\n",
                "            },\n",
                "            new JsonObject\n",
                "            {\n",
                "                { \"role\", \"user\" },\n",
                "                { \"content\", new JsonArray(userPromptParts.ToArray())}\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    { \"model\", modelDeployment },\n",
                "    { \"max_tokens\", 4096 },\n",
                "    { \"temperature\", 0.1 },\n",
                "    { \"top_p\", 0.1 },\n",
                "};\n",
                "\n",
                "string payload = JsonSerializer.Serialize(jsonPayload, new JsonSerializerOptions\n",
                "{\n",
                "    WriteIndented = true\n",
                "});"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "polyglot-notebook"
                }
            },
            "outputs": [],
            "source": [
                "var invoiceData = InvoiceData.Empty;\n",
                "\n",
                "using (HttpClient httpClient = new HttpClient())\n",
                "{\n",
                "    httpClient.BaseAddress = new Uri(visionEndpoint);\n",
                "    httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Bearer {bearerToken}\");\n",
                "    httpClient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\n",
                "\n",
                "    var stringContent = new StringContent(payload, Encoding.UTF8, \"application/json\");\n",
                "\n",
                "    var response = await httpClient.PostAsync(visionEndpoint, stringContent);\n",
                "\n",
                "    if (response.IsSuccessStatusCode)\n",
                "    {\n",
                "        using (var responseStream = await response.Content.ReadAsStreamAsync())\n",
                "        {\n",
                "            // Parse the JSON response using JsonDocument\n",
                "            using (var jsonDoc = await JsonDocument.ParseAsync(responseStream))\n",
                "            {\n",
                "                // Access the message content dynamically\n",
                "                JsonElement jsonElement = jsonDoc.RootElement;\n",
                "                string messageContent = jsonElement.GetProperty(\"choices\")[0].GetProperty(\"message\").GetProperty(\"content\").GetString();\n",
                "\n",
                "                // Output the message content\n",
                "                File.WriteAllText(pdfJsonExtractionName, messageContent);\n",
                "                Console.WriteLine($\"{pdfJsonExtractionName} has been created with the content from the response from the OpenAI API.\");\n",
                "\n",
                "                invoiceData = JsonSerializer.Deserialize<InvoiceData>(messageContent);\n",
                "            }\n",
                "        }\n",
                "    }\n",
                "    else\n",
                "    {\n",
                "        Console.WriteLine(response);\n",
                "    }\n",
                "}"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".NET (C#)",
            "language": "C#",
            "name": ".net-csharp"
        },
        "language_info": {
            "name": "python"
        },
        "polyglot_notebook": {
            "kernelInfo": {
                "defaultKernelName": "csharp",
                "items": [
                    {
                        "aliases": [],
                        "name": "csharp"
                    }
                ]
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
